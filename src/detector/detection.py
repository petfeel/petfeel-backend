# detector/detection.py
import os
import time
import cv2
import requests
import numpy as np
from datetime import datetime
from pathlib import Path
from ultralytics import YOLO
from sklearn.ensemble import IsolationForest
from sklearn.neighbors import LocalOutlierFactor
import google.generativeai as genai
import re
import warnings
import json
import glob
import base64
import io
from sqlalchemy.orm import Session
from db.models.pet import PetProfile
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import aiohttp
import asyncio
import websockets  # ì›¹ì†Œì¼“ ê¸°ëŠ¥ ì¶”ê°€
 
# ê²½ê³  ë©”ì‹œì§€ í•„í„°ë§
warnings.filterwarnings('ignore', category=UserWarning)
 
# í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ
SERVER_URL = os.getenv("SERVER_URL", "http://localhost:8000")  # ì‹¤ì œ ì„œë²„ ì£¼ì†Œë¡œ ë³€ê²½ í•„ìš”
API_EVENT_EP = f"{SERVER_URL}/events"  # /event -> /eventsë¡œ ìˆ˜ì •
WS_SERVER_URL = SERVER_URL.replace("http", "ws")  # WebSocket ì„œë²„ URL
 
# API í‚¤ ì§ì ‘ ì„¤ì •
GOOGLE_API_KEY = "AIzaSyAodNAwhpYmQkLWPA3dv-giw0WppjLhjMY"
genai.configure(api_key=GOOGLE_API_KEY)
LLM = genai.GenerativeModel(model_name="models/gemini-2.5-flash-preview-05-20")
 
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
PROJECT_ROOT = Path(__file__).resolve().parents[1]
 
# ===== ì…ë ¥ ì†ŒìŠ¤ ì„¤ì • =====
# ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ USE_CAMERA = Trueë¡œ ë³€ê²½
# ì˜ìƒ íŒŒì¼ì„ ì‚¬ìš©í•˜ë ¤ë©´ USE_CAMERA = Falseë¡œ ì„¤ì •í•˜ê³  VIDEO_PATH ì§€ì •
USE_CAMERA = False  # True: ì¹´ë©”ë¼ ì‚¬ìš©, False: ë¹„ë””ì˜¤ íŒŒì¼ ì‚¬ìš©
CAMERA_ID = 2 # ì¹´ë©”ë¼ ì‚¬ìš© ì‹œ ì¹´ë©”ë¼ ID
VIDEO_PATH = "videos/test_video.mp4"  # ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
 
# ===== íŒŒë¼ë¯¸í„° ì„¤ì • =====
"""
[ì˜ìƒ ì²˜ë¦¬ ê´€ë ¨ íŒŒë¼ë¯¸í„°]
FRAME_SKIP = 5    # ëª‡ í”„ë ˆì„ë‹¹ 1ë²ˆ ì²˜ë¦¬í• ì§€ ì„¤ì •
                  # ì˜ˆ: 5ë¡œ ì„¤ì • ì‹œ 5í”„ë ˆì„ë§ˆë‹¤ 1ë²ˆ ì²˜ë¦¬ (30fps ê¸°ì¤€ 1ì´ˆì— 6ë²ˆ ì²˜ë¦¬)
                  # ê°’ì´ ì‘ì„ìˆ˜ë¡ ë” ìì£¼ ì²´í¬í•˜ì§€ë§Œ ì²˜ë¦¬ ë¶€í•˜ê°€ ì¦ê°€
                  # ê°’ì´ í´ìˆ˜ë¡ ì²˜ë¦¬ëŠ” ë¹ ë¥´ì§€ë§Œ ë†“ì¹˜ëŠ” í–‰ë™ì´ ë§ì•„ì§ˆ ìˆ˜ ìˆìŒ
                  # ê¶Œì¥ ë²”ìœ„: 3~10
 
WINDOW_SIZE = 5    # í•œ ë²ˆì— ë¶„ì„í•  í”„ë ˆì„ ë¬¶ìŒ í¬ê¸°
                   # ì˜ˆ: 5ë¡œ ì„¤ì • ì‹œ 5í”„ë ˆì„ì„ í•˜ë‚˜ì˜ ë¬¶ìŒìœ¼ë¡œ ë¶„ì„
                   # FRAME_SKIPê³¼ ì—°ê³„ë˜ì–´ ì‹¤ì œ ì‹œê°„ ê³„ì‚°ë¨
                   # í˜„ì¬ ì„¤ì •: 5í”„ë ˆì„ Ã— 5í”„ë ˆì„ ê°„ê²© = 25í”„ë ˆì„(ì•½ 0.8ì´ˆ) ë‹¨ìœ„ë¡œ ë¶„ì„
 
DETECTION_WINDOWS = 5    # ì´ìƒí–‰ë™ ê°ì§€ë¥¼ ìœ„í•´ ì²´í¬í•  ìœˆë„ìš° ìˆ˜
                        # ì˜ˆ: 5ë¡œ ì„¤ì • ì‹œ 5ë²ˆì˜ ì—°ì†ëœ ìœˆë„ìš° ì²´í¬
                        # í˜„ì¬ ì„¤ì •: 5ë²ˆ Ã— 0.8ì´ˆ = ì•½ 4ì´ˆ ë™ì•ˆì˜ í–‰ë™ íŒ¨í„´ ì²´í¬
 
BUFFER_SECONDS = 3     # ì œë¯¸ë‹ˆ ë¶„ì„ ë° DB ì €ì¥ì„ ìœ„í•œ ì˜ìƒ ê¸¸ì´(ì´ˆ)
                      # ì œë¯¸ë‹ˆì— ë³´ë‚¼ ì˜ìƒê³¼ DBì— ì €ì¥í•  ì˜ìƒì˜ ê¸¸ì´
                      # ê°’ì´ í¬ë©´ ë” ì •í™•í•œ ë¶„ì„ì´ ê°€ëŠ¥í•˜ì§€ë§Œ ì²˜ë¦¬ ì‹œê°„ ì¦ê°€
                      # ê¶Œì¥ ë²”ìœ„: 3~5ì´ˆ
 
FPS = 30.0            # ê¸°ë³¸ FPS ì„¤ì •
                      # ëŒ€ë¶€ë¶„ì˜ ì¹´ë©”ë¼/ì˜ìƒì˜ ê¸°ë³¸ê°’ì´ë¯€ë¡œ ìˆ˜ì • ë¶ˆí•„ìš”
 
MAX_FRAMES = int(FPS * BUFFER_SECONDS)  # ë²„í¼ì— ì €ì¥í•  ìµœëŒ€ í”„ë ˆì„ ìˆ˜
                                       # ìë™ ê³„ì‚°ë˜ë¯€ë¡œ ìˆ˜ì • ë¶ˆí•„ìš”
                                       # í˜„ì¬ ì„¤ì •: 30fps Ã— 3ì´ˆ = 90í”„ë ˆì„
 
[ë¯¼ê°ë„ ê´€ë ¨ íŒŒë¼ë¯¸í„°]
STD_MULTIPLIER = 0.5   # ì´ìƒí–‰ë™ ê°ì§€ ë¯¼ê°ë„
                      # ê°’ì´ ì‘ì„ìˆ˜ë¡ ë” ë¯¼ê°í•˜ê²Œ ê°ì§€
                      # ê°’ì´ í´ìˆ˜ë¡ í™•ì‹¤í•œ ì´ìƒí–‰ë™ë§Œ ê°ì§€
                      # ê¶Œì¥ ë²”ìœ„: 0.3~1.0
 
IF_CONTAM = 0.2       # IsolationForest ëª¨ë¸ì˜ ì´ìƒì¹˜ ë¹„ìœ¨
LOF_CONTAM = 0.2      # LocalOutlierFactor ëª¨ë¸ì˜ ì´ìƒì¹˜ ë¹„ìœ¨
                      # ë‘ ê°’ì´ í´ìˆ˜ë¡ ë” ë§ì€ í–‰ë™ì„ ì´ìƒí–‰ë™ìœ¼ë¡œ íŒë‹¨
                      # ê¶Œì¥ ë²”ìœ„: 0.1~0.3
 
[ì‹¤ì œ ì‹œê°„ ê³„ì‚° ì˜ˆì‹œ]
í˜„ì¬ ì„¤ì • ê¸°ì¤€:
1. í”„ë ˆì„ ì²˜ë¦¬: 5í”„ë ˆì„ë§ˆë‹¤ 1ë²ˆ â†’ 1ì´ˆì— 6ë²ˆ ì²˜ë¦¬ (30fps ê¸°ì¤€)
2. í–‰ë™ ë¶„ì„: 5í”„ë ˆì„ Ã— 5ë²ˆ = 25í”„ë ˆì„(ì•½ 0.8ì´ˆ) ë‹¨ìœ„ë¡œ ë¶„ì„
3. ì´ìƒí–‰ë™ ê°ì§€: 5ë²ˆì˜ ì—°ì†ëœ ë¶„ì„ = ì•½ 4ì´ˆ ë™ì•ˆì˜ íŒ¨í„´ ì²´í¬
4. ì˜ìƒ ì €ì¥: ê°ì§€ í›„ 4ì´ˆ ë¶„ëŸ‰ ì €ì¥ ë° ë¶„ì„
 
ì„¤ì • ë³€ê²½ ì‹œ ê³ ë ¤ì‚¬í•­:
1. ë¹ ë¥¸ ê°ì§€ê°€ í•„ìš”í•˜ë©´: FRAME_SKIPê³¼ WINDOW_SIZEë¥¼ ì¤„ì„
2. ì •í™•í•œ ë¶„ì„ì´ í•„ìš”í•˜ë©´: BUFFER_SECONDSë¥¼ ëŠ˜ë¦¼
3. ì €ì¥ ìš©ëŸ‰ ì ˆì•½ì´ í•„ìš”í•˜ë©´: FRAME_SKIPì„ ëŠ˜ë¦¼
"""
 
FRAME_SKIP         = 5   # 2í”„ë ˆì„ë‹¹ 1í”„ë ˆì„ ì²˜ë¦¬ (ì„±ëŠ¥ ìµœì í™”)
WINDOW_SIZE        = 5   # ì´ìƒí–‰ë™ ê°ì§€ ìœˆë„ìš° í¬ê¸°
DETECTION_WINDOWS  = 5  # ì—°ì† ê°ì§€ ìœˆë„ìš° ìˆ˜
ALLOWED_NORMAL     = 1   # í—ˆìš©ë˜ëŠ” ì •ìƒ ìœˆë„ìš° ìˆ˜
FPS               = 30.0  # ê¸°ë³¸ FPS
BUFFER_SECONDS    = 10    # ë²„í¼ í¬ê¸° (ì´ˆ) - ì €ì¥ë˜ëŠ” ì˜ìƒì˜ ê¸¸ì´
MAX_FRAMES        = int(BUFFER_SECONDS * FPS / FRAME_SKIP)  # ìµœëŒ€ í”„ë ˆì„ ìˆ˜
STD_MULTIPLIER    = 0.5 # ì´ìƒì¹˜ ê°ì§€ í‘œì¤€í¸ì°¨ ë°°ìˆ˜
IF_CONTAM         = 0.2 # IsolationForest contamination
LOF_CONTAM        = 0.2  # LocalOutlierFactor contamination
LOF_NEIGHBORS     = 4   # LocalOutlierFactor neighbors
 
# ì¹´ë©”ë¼ ì œì–´ë¥¼ ìœ„í•œ ì „ì—­ ë³€ìˆ˜
camera_running = False
current_camera = None
 
# ì¹´ë©”ë¼ ëª¨ë“œ ì„¤ì •ì„ ìœ„í•œ ì „ì—­ ë³€ìˆ˜
USE_CAMERA = False
 
def set_camera_mode(use_camera: bool):
    """ì¹´ë©”ë¼ ëª¨ë“œ ì„¤ì •ì„ ë³€ê²½í•˜ëŠ” í•¨ìˆ˜"""
    global USE_CAMERA, camera_running
    USE_CAMERA = use_camera
    if not use_camera:
        camera_running = False
 
def get_pet_name(db: Session, pet_id: int) -> str:
    """pet_idë¡œ pet_nameì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜"""
    try:
        pet = db.query(PetProfile).filter(PetProfile.id == pet_id).first()
        return pet.pet_name if pet else "í…ŒìŠ¤íŠ¸ê°•ì•„ì§€"
    except Exception as e:
        print(f"âš ï¸ pet_name ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
        return "í…ŒìŠ¤íŠ¸ê°•ì•„ì§€"
 
# Gemini í”„ë¡¬í”„íŠ¸ â€“ 0~4ë‹¨ê³„ ëª…ì‹œ
def get_prompt(db: Session = None, pet_id: int = None):
    """Gemini í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    if db and pet_id:
        dog_name = get_pet_name(db, pet_id)
    else:
        dog_name = "ë©ë©ê·œ"
       
    return f"""ê°•ì•„ì§€ {dog_name}ì˜ í˜„ì¬ í–‰ë™ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.
ê°•ì•„ì§€ì˜ ìì„¸ì™€ ì›€ì§ì„ì„ ê¸°ë°˜ìœ¼ë¡œ í–‰ë™ì„ í•´ì„í•˜ê³ , ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
 
ì‘ë‹µ í˜•ì‹:
1. í˜„ì¬ í–‰ë™ ì„¤ëª… (1ì¤„)
2. ì‹¬ê°ë„: [0-3]ë‹¨ê³„
- 0ë‹¨ê³„: ì •ìƒì ì¸ í–‰ë™ (í‰ì˜¨, íœ´ì‹, ì¼ìƒì  í™œë™)
- 1ë‹¨ê³„: ì£¼ì˜ ê´€ì°° í•„ìš” (ê³¼ë„í•œ ì›€ì§ì„, ë¶ˆì•ˆí•œ ì§•í›„)
- 2ë‹¨ê³„: ê²½ë¯¸í•œ ë¬¸ì œ í–‰ë™ (ë°˜ë³µì ì¸ ì´ìƒ í–‰ë™)
- 3ë‹¨ê³„: ì‹¬ê°í•œ ë¬¸ì œ í–‰ë™ ë˜ëŠ” ìœ„í—˜ ìƒí™© (ê³µê²©ì„±, ìí•´ ìœ„í—˜, ì¦‰ê° ì¡°ì¹˜ í•„ìš”)
3. ì‹¬ê°ë„ì— ë”°ë¥¸ ëŒ€ì²˜ ë°©ë²• (1-2ì¤„)
4. ì‹¬ê°ë„ê°€ 0 ë‹¨ê³„ì¼ ê²½ìš° ê°•ì•„ì§€ê°€ ë¬´ìŠ¨ í–‰ë™ì„ í•˜ê³  ìˆëŠ”ì§€ ì„¤ëª…í•´ì£¼ì„¸ìš”.
* 3ë‹¨ê³„ ì´ìƒì¼ ê²½ìš° ì‘ë‹µì„ **êµµì€ ê¸€ì”¨**ë¡œ í‘œì‹œ
* ë¶ˆí•„ìš”í•œ ì¸ì‚¬ë§ì´ë‚˜ ì˜ˆì˜ì  í‘œí˜„ì€ ìƒëµ
* ì œê³µëœ ì •ë³´ë§Œìœ¼ë¡œëŠ” íŒŒì•…ì´ ì–´ë ¤ì›Œë„ ìµœëŒ€í•œ íŒŒì•…í•´ì„œ í–‰ë™ ë¶„ì„í•´ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”.
* ë°˜ë“œì‹œ ë‹¨ê³„ë¥¼ ìˆ«ìë¡œ ëª…ì‹œí•´ì£¼ì„¸ìš” (ì˜ˆ: '2ë‹¨ê³„' ë˜ëŠ” 'ë‹¨ê³„: 2')"""
 
# ëª¨ë¸ ë¡œë“œ
MODEL_PATH = PROJECT_ROOT / "dog_pose_model.pt"
print(f"ëª¨ë¸ íŒŒì¼ ê²½ë¡œ: {MODEL_PATH}")
yolo      = YOLO(str(MODEL_PATH))
if_model  = IsolationForest(contamination=IF_CONTAM, random_state=42)
lof_model = LocalOutlierFactor(n_neighbors=LOF_NEIGHBORS, contamination=LOF_CONTAM, novelty=True)
 
def z_norm(a):
    return (a - a.mean()) / (a.std() or 1.0)
 
# WebSocketì„ í†µí•´ ì•Œë¦¼ ì „ì†¡
async def send_notification_ws(event_data, pet_id):
    """
    WebSocketì„ í†µí•´ ì•Œë¦¼ì„ ì „ì†¡í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        event_data: ì´ë²¤íŠ¸ ë°ì´í„° (DBì— ì €ì¥ëœ ê²°ê³¼)
        pet_id: ë°˜ë ¤ë™ë¬¼ ID
    """
    try:
        # ì•Œë¦¼ ë°ì´í„° ì¤€ë¹„
        notification = {
            "type": "notification",
            "event_id": event_data.get("id", 0),
            "pet_id": pet_id,
            "stage": event_data.get("stage", "0"),
            "message": "ë°˜ë ¤ë™ë¬¼ì˜ ì´ìƒí–‰ë™ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "behavior_report": event_data.get("summary", ""),
            "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        }
        
        # WebSocket URL ì¤€ë¹„
        ws_endpoint = f"{WS_SERVER_URL}/notifications/broadcast"
        
        print(f"\nğŸ“£ WebSocket ì•Œë¦¼ ì „ì†¡ ì‹œë„:")
        print(f"   - ì—”ë“œí¬ì¸íŠ¸: {ws_endpoint}")
        
        # WebSocket ì—°ê²° ë° ë©”ì‹œì§€ ì „ì†¡
        try:
            # íƒ€ì„ì•„ì›ƒ ì„¤ì • - ì—°ê²° ë° ì†¡ì‹ ì— ìµœëŒ€ 3ì´ˆë§Œ í—ˆìš©
            async with websockets.connect(ws_endpoint, close_timeout=3) as websocket:
                await websocket.send(json.dumps(notification))
                print("âœ… WebSocket ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ!")
                # ì‘ë‹µì„ ê¸°ë‹¤ë¦¬ì§€ ì•Šê³  ë°”ë¡œ ë¦¬í„´ (ì›ë˜ ì½”ë“œëŠ” ì‘ë‹µì„ ê¸°ë‹¤ë¦¼)
        except websockets.exceptions.WebSocketException as ws_err:
            print(f"âš ï¸ WebSocket ì—°ê²° ì‹¤íŒ¨, HTTP í´ë°± ì‹œë„: {str(ws_err)}")
            
            # WebSocket ì‹¤íŒ¨ ì‹œ HTTPë¡œ í´ë°±
            try:
                async with aiohttp.ClientSession() as session:
                    http_endpoint = f"{SERVER_URL}/notifications"
                    async with session.post(http_endpoint, json=notification, timeout=3) as response:
                        if response.status == 200:
                            print("âœ… HTTP í´ë°± ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ!")
                        else:
                            print(f"âš ï¸ HTTP í´ë°± ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {await response.text()}")
            except asyncio.TimeoutError:
                print("âš ï¸ HTTP ìš”ì²­ íƒ€ì„ì•„ì›ƒ")
            except Exception as http_err:
                print(f"âš ï¸ HTTP í´ë°± ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {str(http_err)}")
                
    except Exception as e:
        print(f"âš ï¸ ì•Œë¦¼ ì „ì†¡ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        # ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨ê°€ ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¤‘ë‹¨ì‹œí‚¤ì§€ ì•Šë„ë¡ ì˜ˆì™¸ë¥¼ ì—¬ê¸°ì„œ ì²˜ë¦¬
 
async def post_event(stage, summary, frames, fps, db: Session = None, pet_id: int = None):
    """
    ì„œë²„ /event ë¡œ ì´ë²¤íŠ¸ ë°ì´í„° ì „ì†¡ ë° ì €ì¥
    """
    try:
        # pet_idê°€ ì—†ëŠ” ê²½ìš° ì˜¤ë¥˜ ì¶œë ¥
        if pet_id is None:
            print("âš ï¸ ê²½ê³ : pet_idê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ 1ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            pet_id = 1
            
        # ê¸°ë³¸ ë°ì´í„° ì¤€ë¹„
        data = {
            'pet_id': pet_id,
            'stage': str(stage),
            'summary': summary,
            'created_at': datetime.now().isoformat()
        }
        
        print(f"\nğŸ“¤ ì„œë²„ë¡œ ì „ì†¡ ì‹œë„ ì¤‘... (URL: {API_EVENT_EP})")
        print(f"- pet_id: {pet_id}")
       
        # ì˜ìƒì´ ìˆëŠ” ê²½ìš°
        if frames is not None and len(frames) > 0:
            try:
                # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
                temp_dir = Path("temp_videos")
                temp_dir.mkdir(exist_ok=True)
               
                current_time = datetime.now().strftime("%Y%m%d_%H%M%S")
                temp_path = temp_dir / f"temp_{current_time}.mp4"
               
                print("\nğŸ“¹ ì˜ìƒ ì €ì¥ ì¤‘...")
                print(f"- í”„ë ˆì„ ìˆ˜: {len(frames)}")
                print(f"- ì˜ìƒ ê¸¸ì´: {len(frames)/fps*FRAME_SKIP:.2f}ì´ˆ")
               
                # ì˜ìƒ ì €ì¥ - ë†’ì€ í’ˆì§ˆ ì„¤ì •
                h, w = frames[0].shape[:2]
                
                # H.264 ì½”ë± ì‚¬ìš© (ë” ë‚˜ì€ í˜¸í™˜ì„±)
                fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # H.264 ì½”ë±
                
                # ë¹„íŠ¸ë ˆì´íŠ¸ì™€ í•´ìƒë„ í–¥ìƒ
                out = cv2.VideoWriter(
                    str(temp_path), 
                    fourcc, 
                    fps/FRAME_SKIP,  # í”„ë ˆì„ ë ˆì´íŠ¸ 
                    (w, h),  # í•´ìƒë„
                    True   # ì»¬ëŸ¬ ì˜ìƒ
                )
                
                # í”„ë ˆì„ì´ ì ì„ ê²½ìš° ë°˜ë³µí•˜ì—¬ ìµœì†Œ ê¸¸ì´ ë³´ì¥ (ìµœì†Œ 2ì´ˆ)
                min_frames = int(2 * fps / FRAME_SKIP)
                
                if len(frames) < min_frames:
                    print(f"âš ï¸ í”„ë ˆì„ì´ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤. ë°˜ë³µí•˜ì—¬ ìµœì†Œ {min_frames}ê°œ í™•ë³´...")
                    # í”„ë ˆì„ ë°˜ë³µí•˜ì—¬ ìµœì†Œ ê¸¸ì´ ë³´ì¥
                    repeated_frames = []
                    while len(repeated_frames) < min_frames:
                        repeated_frames.extend(frames)
                    frames = repeated_frames[:min_frames]
                    print(f"âœ… í”„ë ˆì„ ë°˜ë³µ ì™„ë£Œ: {len(frames)}ê°œ")
               
                # ì˜ìƒ ì €ì¥ (ê° í”„ë ˆì„ í’ˆì§ˆ ì²´í¬)
                frames_written = 0
                for frame in frames:
                    if frame is None or frame.size == 0:
                        print(f"âš ï¸ ë¹ˆ í”„ë ˆì„ ê±´ë„ˆëœ€ ({frames_written}/{len(frames)})")
                        continue
                        
                    # í”„ë ˆì„ í’ˆì§ˆ í–¥ìƒ (ì„ íƒ ì‚¬í•­)
                    # frame = cv2.GaussianBlur(frame, (3, 3), 0)  # ë…¸ì´ì¦ˆ ê°ì†Œ
                    
                    out.write(frame)
                    frames_written += 1
                
                # ë¹„ë””ì˜¤ ë¼ì´í„° ì¢…ë£Œ ë° ìì› í•´ì œ
                out.release()
                
                print(f"âœ… ì˜ìƒ ì €ì¥ ì™„ë£Œ: {frames_written}/{len(frames)} í”„ë ˆì„")
                
                # íŒŒì¼ì´ ì œëŒ€ë¡œ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸
                if os.path.exists(temp_path):
                    file_size = os.path.getsize(temp_path)
                    if file_size < 1000:  # íŒŒì¼ì´ ë„ˆë¬´ ì‘ìœ¼ë©´ ë¬¸ì œ ìˆìŒ
                        print(f"âš ï¸ ì €ì¥ëœ íŒŒì¼ì´ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤: {file_size}ë°”ì´íŠ¸")
                        # íŒŒì¼ ê²€ì‚¬ë¥¼ ìœ„í•´ ì½ê¸° ì‹œë„
                        cap = cv2.VideoCapture(str(temp_path))
                        if not cap.isOpened():
                            print("âŒ ìƒì„±ëœ ì˜ìƒ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
                            return None
                        cap.release()
                else:
                    print("âŒ ì˜ìƒ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
                    return None
               
                # íŒŒì¼ í¬ê¸° í™•ì¸
                file_size = os.path.getsize(temp_path)
                print(f"ğŸ“¤ ì„œë²„ë¡œ ì „ì†¡ ì¤‘... (í¬ê¸°: {file_size/1024:.1f}KB)")
               
                # íŒŒì¼ ì „ì†¡
                async with aiohttp.ClientSession() as session:
                    data = aiohttp.FormData()
                    data.add_field('pet_id', str(pet_id))
                    data.add_field('stage', str(stage))
                    data.add_field('summary', summary)
                    data.add_field('created_at', datetime.now().isoformat())
                   
                    with open(temp_path, 'rb') as f:
                        file_contents = f.read()
                        data.add_field('video_data',
                                     file_contents,
                                     filename=f"{current_time}.mp4",
                                     content_type='video/mp4')
                                     
                        # ì˜ìƒ ë¯¸ë¦¬ë³´ê¸°ë¥¼ ë¡œì»¬ì— ì €ì¥ (ë””ë²„ê¹…ìš©)
                        preview_dir = Path("video_previews")
                        preview_dir.mkdir(exist_ok=True)
                        preview_path = preview_dir / f"{current_time}.mp4"
                        with open(preview_path, 'wb') as preview_file:
                            preview_file.write(file_contents)
                            print(f"ğŸ’¾ ë¯¸ë¦¬ë³´ê¸° ì˜ìƒ ì €ì¥ë¨: {preview_path}")
                       
                        # POST ìš”ì²­ ì „ì†¡
                        async with session.post(API_EVENT_EP, data=data, timeout=30) as response:
                            if response.status == 200:
                                result = await response.json()
                                print("âœ… DB ì €ì¥ ì™„ë£Œ!")
                                # WebSocket ì•Œë¦¼ ì „ì†¡
                                await send_notification_ws(result, pet_id)
                                return result
                            else:
                                response_text = await response.text()
                                print(f"âš ï¸ DB ì €ì¥ ì‹¤íŒ¨: ìƒíƒœ ì½”ë“œ {response.status}")
                                print(f"ì„œë²„ ì‘ë‹µ: {response_text}")
                                return None
               
            except Exception as e:
                print(f"âš ï¸ ì˜ìƒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                import traceback
                print(traceback.format_exc())
                return None
            finally:
                # ì„ì‹œ íŒŒì¼ ì •ë¦¬
                if os.path.exists(temp_path):
                    os.remove(temp_path)
               
        else:
            # ì˜ìƒ ì—†ëŠ” ê²½ìš° ê°„ë‹¨íˆ ì²˜ë¦¬
            async with aiohttp.ClientSession() as session:
                data['created_at'] = datetime.now().isoformat()
                async with session.post(API_EVENT_EP, data=data) as response:
                    if response.status == 200:
                        result = await response.json()
                        print("âœ… DB ì €ì¥ ì™„ë£Œ!")
                        # WebSocket ì•Œë¦¼ ì „ì†¡
                        await send_notification_ws(result, pet_id)
                        return result
                    print(f"âš ï¸ DB ì €ì¥ ì‹¤íŒ¨: {await response.text()}")
                    return None
               
    except Exception as e:
        print(f"âš ï¸ ì „ì²´ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
        import traceback
        print(traceback.format_exc())
        return None
 
async def analyze_with_gemini(frames_count, db: Session = None, pet_id: int = None):
    """
    Gemini AIë¥¼ ì‚¬ìš©í•œ í–‰ë™ ë¶„ì„
   
    ë§¤ê°œë³€ìˆ˜:
    - frames_count: ë¶„ì„í•  í”„ë ˆì„ ìˆ˜
    - db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
    - pet_id: ë°˜ë ¤ë™ë¬¼ ID
   
    ë°˜í™˜ê°’:
    - stage: í–‰ë™ ë‹¨ê³„ (0-4)
    - text: ë¶„ì„ ê²°ê³¼ í…ìŠ¤íŠ¸
    """
    try:
        print("\nğŸ¤– Gemini ë¶„ì„ ì‹œì‘...")
        print(f"- pet_id: {pet_id}")
        
        # ë¶„ì„í•  ì˜ìƒ ì°¾ê¸°
        gemini_videos = sorted(glob.glob('gemini_videos/*.mp4'))
        if not gemini_videos:
            print("âš ï¸ ë¶„ì„í•  ì˜ìƒ ì—†ìŒ")
            return 0, "ë¶„ì„ ì‹¤íŒ¨: ì˜ìƒ ì—†ìŒ"
           
        latest_video = gemini_videos[-1]
        print(f"ğŸ“ ë¶„ì„í•  ì˜ìƒ: {latest_video}")
       
        if not os.path.exists(latest_video):
            print(f"âš ï¸ ì˜ìƒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {latest_video}")
            return 0, "ë¶„ì„ ì‹¤íŒ¨: ì˜ìƒ íŒŒì¼ ì—†ìŒ"
           
        file_size = os.path.getsize(latest_video)
        print(f"ğŸ“Š ì˜ìƒ íŒŒì¼ í¬ê¸°: {file_size/1024:.1f}KB")
       
        if file_size == 0:
            print("âš ï¸ ì˜ìƒ íŒŒì¼ì´ ë¹„ì–´ìˆìŒ")
            return 0, "ë¶„ì„ ì‹¤íŒ¨: ë¹ˆ ì˜ìƒ íŒŒì¼"
       
        print("ğŸ”„ ì˜ìƒ íŒŒì¼ ì—…ë¡œë“œ ì¤‘...")
        video_file = await asyncio.to_thread(genai.upload_file, path=latest_video)
        print(f"âœ… ì—…ë¡œë“œ ì™„ë£Œ: {video_file.name}")
       
        print("â³ ì˜ìƒ ì²˜ë¦¬ ëŒ€ê¸° ì¤‘...")
        retry_count = 0
        while video_file.state.name == "PROCESSING" and retry_count < 10:
            await asyncio.sleep(0.5)
            video_file = await asyncio.to_thread(genai.get_file, video_file.name)
            retry_count += 1
            print(f"   - ìƒíƒœ: {video_file.state.name} (ì‹œë„: {retry_count})")
           
        if video_file.state.name == "FAILED" or retry_count >= 10:
            print(f"âš ï¸ ì˜ìƒ ì²˜ë¦¬ ì‹¤íŒ¨ (ìƒíƒœ: {video_file.state.name})")
            return 0, "ë¶„ì„ ì‹¤íŒ¨: ì˜ìƒ ì²˜ë¦¬ ì˜¤ë¥˜"
 
        print("\nğŸ“ í”„ë¡¬í”„íŠ¸ ì „ì†¡...")
       
        resp = await asyncio.to_thread(LLM.generate_content, [get_prompt(db, pet_id), video_file])
       
        if not resp:
            print("âš ï¸ ì‘ë‹µ ì—†ìŒ")
            return 0, "ë¶„ì„ ì‹¤íŒ¨: ì‘ë‹µ ì—†ìŒ"
           
        text = resp.text.strip()
        print("\nâœ… ë¶„ì„ ì™„ë£Œ:")
        print(text)
       
        stage = 0
        if "ë‹¨ê³„" in text:
            stage_match = re.search(r'(\d+)ë‹¨ê³„|ë‹¨ê³„[:\s]*(\d+)|ì‹¬ê°ë„[:\s]*(\d+)', text)
            if stage_match:
                stage = int(stage_match.group(1) or stage_match.group(2) or stage_match.group(3))
       
        if stage < 0 or stage > 4:
            print(f"âš ï¸ ì˜ëª»ëœ ë‹¨ê³„ ê°’ ({stage})")
            stage = 0
           
        print(f"\nğŸ“Š ë¶„ì„ ê²°ê³¼:")
        print(f"- ë‹¨ê³„: {stage}")
        print(f"- í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)}ì")
       
        return stage, text
       
    except Exception as e:
        print(f"\nâŒ ë¶„ì„ ì˜¤ë¥˜:")
        print(f"- ìœ í˜•: {type(e).__name__}")
        print(f"- ë‚´ìš©: {str(e)}")
        import traceback
        print(f"- ìƒì„¸:\n{traceback.format_exc()}")
        return 0, f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
 
async def process_video(video_path: str = None, use_camera: bool = None, db: Session = None, pet_id: int = None) -> dict:
    """
    ë¹„ë””ì˜¤ ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜
    ì¹´ë©”ë¼ ë˜ëŠ” ë¹„ë””ì˜¤ íŒŒì¼ì—ì„œ í”„ë ˆì„ì„ ì½ì–´ ì²˜ë¦¬
 
    Args:
        video_path: ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ (use_camera=Falseì¼ ë•Œ ì‚¬ìš©)
        use_camera: Trueë©´ ì¹´ë©”ë¼ ì‚¬ìš©, Falseë©´ ë¹„ë””ì˜¤ íŒŒì¼ ì‚¬ìš© (Noneì´ë©´ ì „ì—­ USE_CAMERA ì‚¬ìš©)
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        pet_id: ë°˜ë ¤ë™ë¬¼ ID
    """
    global camera_running, USE_CAMERA
    
    print("\nğŸ”„ process_video í•¨ìˆ˜ í˜¸ì¶œ:")
    print(f"- video_path: {video_path}")
    print(f"- use_camera: {use_camera}")
    print(f"- pet_id: {pet_id}")
   
    # íŒŒì¼ ê²½ë¡œê°€ ìˆìœ¼ë©´ ë¬´ì¡°ê±´ íŒŒì¼ ëª¨ë“œë¡œ ì„¤ì •
    if video_path:
        USE_CAMERA = False
    # íŒŒì¼ ê²½ë¡œê°€ ì—†ê³  use_cameraê°€ ì§€ì •ëœ ê²½ìš° í•´ë‹¹ ê°’ ì‚¬ìš©
    elif use_camera is not None:
        USE_CAMERA = use_camera
   
    print("ğŸ¥ ì˜ìƒ ì†ŒìŠ¤ ì´ˆê¸°í™” ì¤‘...")
    print(f"- ëª¨ë“œ: {'ì¹´ë©”ë¼' if USE_CAMERA else 'ë¹„ë””ì˜¤ íŒŒì¼'}")
   
    if USE_CAMERA:
        # ì¹´ë©”ë¼ ëª¨ë“œ
        camera_running = True
        cap = cv2.VideoCapture(CAMERA_ID)
        if not cap.isOpened():
            print(f"ì¹´ë©”ë¼ {CAMERA_ID} ì—´ê¸° ì‹¤íŒ¨, ì¹´ë©”ë¼ 0 ì‹œë„...")
            cap = cv2.VideoCapture(0)
            if not cap.isOpened():
                print("âŒ ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
                camera_running = False
                return {"error": "ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}
        print(f"âœ… ì¹´ë©”ë¼ ì—°ê²° ì„±ê³µ")
        try:
            cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
            cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
        except Exception as e:
            print(f"âš ï¸ í•´ìƒë„ ì„¤ì • ì‹¤íŒ¨ (ë¬´ì‹œí•˜ê³  ê³„ì†): {str(e)}")
    else:
        # ë¹„ë””ì˜¤ íŒŒì¼ ëª¨ë“œ
        if not video_path:
            raise ValueError("ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œê°€ í•„ìš”í•©ë‹ˆë‹¤")
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            print(f"âŒ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
            return {"error": "ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}
        print(f"âœ… ë¹„ë””ì˜¤ íŒŒì¼ ë¡œë“œë¨: {video_path}")
 
    # ë¹„ë””ì˜¤ ì •ë³´ ì¶œë ¥
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS) or FPS
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
 
    print(f"- í•´ìƒë„: {width}x{height}")
    print(f"- FPS: {fps:.1f}")
    print(f"- í”„ë ˆì„ ìŠ¤í‚µ: {FRAME_SKIP} (ì²˜ë¦¬ FPS: {fps/FRAME_SKIP:.1f})")
    print(f"- ë²„í¼ í¬ê¸°: {BUFFER_SECONDS}ì´ˆ ({MAX_FRAMES} í”„ë ˆì„)")
    if not USE_CAMERA:
        print(f"- ì´ í”„ë ˆì„ ìˆ˜: {total_frames}")
        print(f"- ì˜ˆìƒ ì¬ìƒ ì‹œê°„: {total_frames/fps:.1f}ì´ˆ")
 
    # ìœˆë„ìš° ìƒì„±
    window_name = "Dog Pose Detection"
    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
    cv2.resizeWindow(window_name, 1280, 720)
    cv2.moveWindow(window_name, 0, 0)
 
    # ì´ˆê¸°í™”
    features = []
    frames_vis = []
    frames_original = []
    frame_idxs = []
    frame_times = []
    frame_no = 0
    last_event_time = 0
    is_recording = False
    current_stage = 0
    current_summary = ""
    recording_start_time = 0
    abnormal_windows = []
    continuous_detection = False
 
    # Gemini ë¹„ë””ì˜¤ ì €ì¥ í´ë” ìƒì„±
    os.makedirs('gemini_videos', exist_ok=True)
 
    try:
        while camera_running if USE_CAMERA else True:
            ret, frame = cap.read()
            if not ret:
                if USE_CAMERA:
                    print("âš ï¸ ì¹´ë©”ë¼ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    continue
                else:
                    print("âœ… ì˜ìƒ ì²˜ë¦¬ ì™„ë£Œ!")
                    break
               
            if frame is None or frame.size == 0:
                print("âš ï¸ ë¹ˆ í”„ë ˆì„ì„ ë°›ì•˜ìŠµë‹ˆë‹¤.")
                continue
               
            frame_no += 1
            current_time = time.time()
           
            # ì§„í–‰ë¥  í‘œì‹œ (ë¹„ë””ì˜¤ íŒŒì¼ ëª¨ë“œì¼ ë•Œë§Œ)
            if not USE_CAMERA and frame_no % 30 == 0:
                progress = (frame_no / total_frames) * 100
                print(f"\rì§„í–‰ë¥ : {progress:.1f}%", end="")
 
            # YOLOë¡œ í¬ì¦ˆ ì˜ˆì¸¡ ë° ì‹œê°í™” (ë§¤ í”„ë ˆì„ ì²˜ë¦¬)
            result = yolo.predict(frame, conf=0.7, verbose=False)[0]
            vis = result.plot()
 
            # í™”ë©´ì— ìƒíƒœ í‘œì‹œ
            fps_text = f"FPS: {fps/FRAME_SKIP:.1f}"
            cv2.putText(vis, fps_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
           
            status = "ì •ìƒ" if not is_recording else "ì´ìƒí–‰ë™ ê°ì§€ ì¤‘"
            cv2.putText(vis, status, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1,
                       (0, 255, 0) if not is_recording else (0, 0, 255), 2)
 
            # í™”ë©´ í‘œì‹œ
            cv2.imshow(window_name, vis)
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                print("\nì‚¬ìš©ìê°€ ì¢…ë£Œë¥¼ ìš”ì²­í–ˆìŠµë‹ˆë‹¤.")
                break
            elif key == ord('f'):
                if cv2.getWindowProperty(window_name, cv2.WND_PROP_FULLSCREEN) == cv2.WINDOW_FULLSCREEN:
                    cv2.setWindowProperty(window_name, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_NORMAL)
                else:
                    cv2.setWindowProperty(window_name, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)
 
            # ì´ìƒí–‰ë™ ê°ì§€ëŠ” FRAME_SKIP ê°„ê²©ìœ¼ë¡œ
            if frame_no % FRAME_SKIP != 0:
                continue
 
            # ì´ìƒí–‰ë™ ê°ì§€ ë¡œì§
            if result.keypoints is not None and len(result.keypoints.data) > 0:
                kpts = result.keypoints.data[0]
                if kpts.shape[0] == 24:
                    # íŠ¹ì§•ì  ì¶”ì¶œ
                    pelvis = kpts[14][:2]
                    l_sh, r_sh = kpts[11][:2], kpts[12][:2]
                    scale = np.linalg.norm(l_sh - r_sh) or 1.0
 
                    feat = []
                    for x, y, v in kpts:
                        if v < 0.5:
                            feat += [0.0, 0.0]
                        else:
                            feat += [(x - pelvis[0]) / scale,
                                    (y - pelvis[1]) / scale]
                    features.append(feat)
                    frames_vis.append(vis.copy())
                    frames_original.append(frame.copy())
                    frame_idxs.append(frame_no)
                    frame_times.append(current_time)
 
                    # ì´ìƒí–‰ë™ ê°ì§€
                    if len(features) >= WINDOW_SIZE:
                        X = np.array(features[-WINDOW_SIZE:])
                        if_model.fit(X)
                        lof_model.fit(X)
                        if_scores = if_model.decision_function(X)
                        lof_scores = lof_model.decision_function(X)
                        combined = (z_norm(if_scores) + z_norm(lof_scores)) / 2.0
                       
                        threshold = combined.mean() - STD_MULTIPLIER * combined.std()
                        is_abnormal = combined[-1] < threshold
 
                        abnormal_windows.append(is_abnormal)
                        if len(abnormal_windows) > DETECTION_WINDOWS:
                            abnormal_windows.pop(0)
 
                        if len(abnormal_windows) == DETECTION_WINDOWS:
                            abnormal_count = sum(abnormal_windows)
                            if abnormal_count >= (DETECTION_WINDOWS - ALLOWED_NORMAL) and not continuous_detection:
                                continuous_detection = True
                                is_recording = True
                                recording_start_time = time.time()
                                frames_vis = []
                                frames_original = []
                                print("\nğŸ” ì—°ì†ì ì¸ ì´ìƒí–‰ë™ ê°ì§€ - ì˜ìƒ ìˆ˜ì§‘ ì‹œì‘")
 
                        if is_recording:
                            current_duration = current_time - recording_start_time
                            if current_duration >= BUFFER_SECONDS:
                                print(f"\nğŸ“¹ ì˜ìƒ ìˆ˜ì§‘ ì™„ë£Œ:")
                                print(f"   - ìˆ˜ì§‘ëœ í”„ë ˆì„ ìˆ˜: {len(frames_original)}")
                                print(f"   - ëª©í‘œ í”„ë ˆì„ ìˆ˜: {MAX_FRAMES}")
                                print(f"   - ì‹¤ì œ ìˆ˜ì§‘ ì‹œê°„: {current_duration:.2f}ì´ˆ")
                                print(f"   - ëª©í‘œ ìˆ˜ì§‘ ì‹œê°„: {BUFFER_SECONDS}ì´ˆ")
 
                                try:
                                    # Gemini ë¶„ì„ìš© ì„ì‹œ ì˜ìƒ ìƒì„±
                                    timestamp_str = datetime.now().strftime("%Y%m%d_%H%M%S")
                                    temp_video_path = os.path.join("gemini_videos", f"temp_{timestamp_str}.mp4")
                                    print(f"\nğŸ’¾ ë¶„ì„ìš© ì˜ìƒ ì €ì¥ ì¤‘: {temp_video_path}")
                                   
                                    target_fps = fps / FRAME_SKIP
                                    h, w = frames_original[0].shape[:2]
                                   
                                    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
                                    out = cv2.VideoWriter(temp_video_path, fourcc, target_fps, (w, h))
                                   
                                    frames_written = 0
                                    for frame in frames_original:
                                        if frame is None or frame.size == 0:
                                            print(f"âš ï¸ ë¹ˆ í”„ë ˆì„ ê±´ë„ˆëœ€ ({frames_written}/{len(frames_original)})")
                                            continue
                                        out.write(frame)
                                        frames_written += 1
                                   
                                    out.release()
                                    
                                    # íŒŒì¼ ê²€ì¦
                                    if os.path.exists(temp_video_path):
                                        file_size = os.path.getsize(temp_video_path)
                                        print(f"ğŸ“Š ì €ì¥ëœ ë¶„ì„ìš© ì˜ìƒ í¬ê¸°: {file_size/1024:.1f}KB")
                                        
                                        if file_size < 1000:  # íŒŒì¼ì´ ë„ˆë¬´ ì‘ìœ¼ë©´ ë¬¸ì œ ìˆìŒ
                                            print(f"âš ï¸ ì €ì¥ëœ ë¶„ì„ìš© ì˜ìƒì´ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤!")
                                    else:
                                        print(f"âŒ ë¶„ì„ìš© ì˜ìƒ ì €ì¥ ì‹¤íŒ¨!")
                                    
                                    time.sleep(0.5)

                                    # ì œë¯¸ë‹ˆ ë¶„ì„ ì‹¤í–‰
                                    analysis_start_time = time.time()
                                    current_stage, current_summary = await analyze_with_gemini(len(frames_original), db, pet_id)
                                    print(f"â±ï¸ ì œë¯¸ë‹ˆ ë¶„ì„ ì‹œê°„: {time.time() - analysis_start_time:.2f}ì´ˆ")
 
                                    # 0ë‹¨ê³„(ì •ìƒ)ì™€ 1~3ë‹¨ê³„(ì´ìƒí–‰ë™) êµ¬ë¶„ ì²˜ë¦¬
                                    if current_stage > 0:
                                        # 1~3ë‹¨ê³„: ì˜ìƒê³¼ í•¨ê»˜ ì €ì¥
                                        print(f"ğŸ“ ì´ìƒí–‰ë™ ê°ì§€ (ë‹¨ê³„: {current_stage}) - ì˜ìƒê³¼ í•¨ê»˜ ì €ì¥")
                                        result = await post_event(current_stage,
                                                                current_summary,
                                                                frames_original,  # ì˜ìƒ í¬í•¨
                                                                fps,
                                                                db=db,
                                                                pet_id=pet_id)
                                        if result:
                                            print(f"âœ… DB ì €ì¥ ì™„ë£Œ!")
                                            print(f"   - í–‰ë™ ë‹¨ê³„: {current_stage}")
                                            # WebSocket ì•Œë¦¼ ì „ì†¡
                                            await send_notification_ws(result, pet_id)
                                        else:
                                            print("âš ï¸ DB ì €ì¥ ì‹¤íŒ¨")
                                    else:
                                        # 0ë‹¨ê³„: ì˜ìƒ ì—†ì´ ì„¤ëª…ë§Œ ì €ì¥
                                        print(f"ğŸ“ ì •ìƒ í–‰ë™ ê°ì§€ (ë‹¨ê³„: {current_stage}) - ì„¤ëª…ë§Œ ì €ì¥")
                                        result = await post_event(current_stage,
                                                                current_summary,
                                                                None,  # ì˜ìƒ ì œì™¸
                                                                fps,
                                                                db=db,
                                                                pet_id=pet_id)
                                        if result:
                                            print(f"âœ… DB ì €ì¥ ì™„ë£Œ! (ì˜ìƒ ì—†ìŒ)")
                                            print(f"   - í–‰ë™ ë‹¨ê³„: {current_stage}")
                                            # WebSocket ì•Œë¦¼ ì „ì†¡
                                            await send_notification_ws(result, pet_id)
                                        else:
                                            print("âš ï¸ DB ì €ì¥ ì‹¤íŒ¨")
 
                                except Exception as e:
                                    print(f"âŒ ì˜ìƒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:")
                                    print(f"   - ë‚´ìš©: {str(e)}")
                                    return {"error": "ì˜ìƒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤"}
                                finally:
                                    if os.path.exists(temp_video_path):
                                        os.remove(temp_video_path)
 
                                # ìƒíƒœ ì´ˆê¸°í™”
                                frames_vis = []
                                frames_original = []
                                frame_times = []
                                is_recording = False
                                continuous_detection = False
                                abnormal_windows = []
                                current_stage = 0
                                current_summary = ""
 
                    # ë²„í¼ ê´€ë¦¬
                    if len(features) > WINDOW_SIZE:
                        features.pop(0)
                    if len(frames_vis) > MAX_FRAMES:
                        frames_vis.pop(0)
                    if len(frames_original) > MAX_FRAMES:
                        frames_original.pop(0)
                    if len(frame_idxs) > MAX_FRAMES:
                        frame_idxs.pop(0)
                    if len(frame_times) > MAX_FRAMES:
                        frame_times.pop(0)
 
    finally:
        camera_running = False
        cap.release()
        cv2.destroyAllWindows()
        return {"message": "ë¹„ë””ì˜¤ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤"}
 
if __name__ == "__main__":
    import sys
    if len(sys.argv) > 1:
        video_path = sys.argv[1]
        if sys.argv[2] if len(sys.argv) > 2 else None == "camera":
            asyncio.run(process_video(use_camera=True))
        else:
            asyncio.run(process_video(video_path=video_path))
    else:
        print("ì‚¬ìš©ë²•: python detection.py <ë¹„ë””ì˜¤_íŒŒì¼_ê²½ë¡œ | camera>")
 
"""
[ë°˜ë ¤ê²¬ í–‰ë™ ê°ì§€ ì‹œìŠ¤í…œ - ë©”ì¸ ê°ì§€ ëª¨ë“ˆ]
 
ì‹œìŠ¤í…œ êµ¬ì„± ë° ë°ì´í„° íë¦„:
1. ì…ë ¥ ì†ŒìŠ¤ ì²˜ë¦¬
   - ì¹´ë©”ë¼ ë˜ëŠ” ë¹„ë””ì˜¤ íŒŒì¼ì—ì„œ í”„ë ˆì„ ì½ê¸°
   - FRAME_SKIPì„ í†µí•œ ì„±ëŠ¥ ìµœì í™”
 
2. í–‰ë™ ê°ì§€ íŒŒì´í”„ë¼ì¸
   - YOLO ëª¨ë¸: ê°•ì•„ì§€ í¬ì¦ˆ ê°ì§€
   - IsolationForest/LOF: ì´ìƒí–‰ë™ íŒ¨í„´ ê°ì§€
   - ì—°ì†ëœ ì´ìƒí–‰ë™ ì²´í¬ (DETECTION_WINDOWS)
 
3. ì˜ìƒ ì²˜ë¦¬ ë° ì €ì¥
   - ë²„í¼ ê´€ë¦¬: MAX_FRAMES ê¸°ì¤€
   - ì„ì‹œ ì €ì¥: gemini_videos/ ë””ë ‰í† ë¦¬
   - ìµœì¢… ì €ì¥: temp_videos/ ë””ë ‰í† ë¦¬
 
4. Gemini AI ë¶„ì„
   - í–‰ë™ íŒ¨í„´ ë¶„ì„
   - ë‹¨ê³„ ë¶„ë¥˜ (0-3)
   - ìƒì„¸ í–‰ë™ ì„¤ëª… ìƒì„±
 
5. ì„œë²„ í†µì‹ 
   - /events ì—”ë“œí¬ì¸íŠ¸ë¡œ ë°ì´í„° ì „ì†¡
   - ì˜ìƒ ë°ì´í„° multipart/form-data í˜•ì‹ ì‚¬ìš©
   - ë¶„ì„ ê²°ê³¼ DB ì €ì¥
 
ì£¼ìš” ë°ì´í„° í¬ì¸íŠ¸:
- features: ê°•ì•„ì§€ í¬ì¦ˆì˜ íŠ¹ì§•ì  ë°ì´í„°
- frames_vis: ì‹œê°í™”ëœ í”„ë ˆì„ ë²„í¼
- frames_original: ì›ë³¸ í”„ë ˆì„ ë²„í¼
- abnormal_windows: ì´ìƒí–‰ë™ ê°ì§€ ìœˆë„ìš°
 
ì—ëŸ¬ ì²˜ë¦¬:
- íŒŒì¼ ì €ì¥/ì‚­ì œ ì‹¤íŒ¨
- ì„œë²„ í†µì‹  ì˜¤ë¥˜
- Gemini API ì˜¤ë¥˜
- ì˜ìƒ ì²˜ë¦¬ ì˜¤ë¥˜
 
ì„±ëŠ¥ ìµœì í™”:
- FRAME_SKIPìœ¼ë¡œ ì²˜ë¦¬ëŸ‰ ì¡°ì ˆ
- ë²„í¼ í¬ê¸° ê´€ë¦¬
- ì´ì „ ë¶„ì„ ì˜ìƒ ìë™ ì •ë¦¬
"""
 